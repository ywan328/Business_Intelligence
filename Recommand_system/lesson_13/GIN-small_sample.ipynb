{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user_id  merchant_id  label origin  prob\n",
      "0       365952         1203    0.0  train   NaN\n",
      "1        42624          946    0.0  train   NaN\n",
      "2       240000         2278    0.0  train   NaN\n",
      "3       177792          951    0.0  train   NaN\n",
      "4       322944         1892    0.0  train   NaN\n",
      "...        ...          ...    ...    ...   ...\n",
      "23888    47231         1748    NaN   test   0.0\n",
      "23889    59519          798    NaN   test   0.0\n",
      "23890   263039          639    NaN   test   0.0\n",
      "23891   263039         3954    NaN   test   0.0\n",
      "23892   423551         2954    NaN   test   0.0\n",
      "\n",
      "[23893 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# 加载小样本\n",
    "user_log = pd.read_csv('./sample_user_log.csv', dtype={'time_stamp':'str'})\n",
    "user_info = pd.read_csv('./sample_user_info.csv')\n",
    "train_data1 = pd.read_csv('./train.csv')\n",
    "submission = pd.read_csv('./test.csv')\n",
    "train_data = pd.read_csv('./train_format2.csv')\n",
    "\n",
    "train_data1['origin'] = 'train'\n",
    "submission['origin'] = 'test'\n",
    "matrix = pd.concat([train_data1, submission], ignore_index=True, sort=False)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user_id  merchant_id label origin  prob  age_range  gender\n",
      "0        16497         1203   0.0  train   NaN          0       1\n",
      "1         1950          946   0.0  train   NaN          2       0\n",
      "2        10829         2278   0.0  train   NaN          3       0\n",
      "3         7974          951   0.0  train   NaN          0       1\n",
      "4        14604         1892   0.0  train   NaN          7       0\n",
      "...        ...          ...   ...    ...   ...        ...     ...\n",
      "23888     2157         1748   nan   test   0.0          0       0\n",
      "23889     2673          798   nan   test   0.0          3       0\n",
      "23890    11847          639   nan   test   0.0          2       1\n",
      "23891    11847         3953   nan   test   0.0          2       1\n",
      "23892    19079         2954   nan   test   0.0          4       0\n",
      "\n",
      "[23893 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# 使用merchant_id（原列名seller_id）\n",
    "user_log.rename(columns={'seller_id':'merchant_id'}, inplace=True)\n",
    "# 格式化\n",
    "user_log['user_id'] = user_log['user_id'].astype('int32')\n",
    "user_log['merchant_id'] = user_log['merchant_id'].astype('int32')\n",
    "user_log['item_id'] = user_log['item_id'].astype('int32')\n",
    "user_log['cat_id'] = user_log['cat_id'].astype('int32')\n",
    "user_log['brand_id'].fillna(0, inplace=True)\n",
    "user_log['brand_id'] = user_log['brand_id'].astype('int32')\n",
    "user_log['time_stamp'] = pd.to_datetime(user_log['time_stamp'], format='%H%M')\n",
    "\n",
    "# 对离散特征做LabelEncoder\n",
    "lbe_merchant_id=LabelEncoder()\n",
    "lbe_merchant_id.fit(np.r_[0,user_log['merchant_id'].values])\n",
    "user_log['merchant_id']=lbe_merchant_id.transform(user_log['merchant_id'])\n",
    "matrix['merchant_id']=lbe_merchant_id.transform(matrix['merchant_id'])\n",
    "\n",
    "lbe_user_id=LabelEncoder()\n",
    "user_log['user_id']=lbe_user_id.fit_transform(user_log['user_id'])\n",
    "user_info['user_id']=lbe_user_id.transform(user_info['user_id'])\n",
    "matrix['user_id']=lbe_user_id.transform(matrix['user_id'])\n",
    "\n",
    "lbe_item_id=LabelEncoder()\n",
    "user_log['item_id']=lbe_item_id.fit_transform(user_log['item_id'])\n",
    "lbe_cat_id=LabelEncoder()\n",
    "user_log['cat_id']=lbe_cat_id.fit_transform(user_log['cat_id'])\n",
    "lbe_brand_id=LabelEncoder()\n",
    "user_log['brand_id']=lbe_brand_id.fit_transform(user_log['brand_id'])\n",
    "\n",
    "user_log['merchant_id'].max(),user_log['user_id'].max()\n",
    "matrix = matrix.merge(user_info, on='user_id', how='left')\n",
    "\n",
    "# 1 for <18; 2 for [18,24]; 3 for [25,29]; 4 for [30,34]; 5 for [35,39]; 6 for [40,49]; 7 and 8 for >= 50; 0 and NULL for unknown\n",
    "matrix['age_range'].fillna(0, inplace=True)\n",
    "# 0:female, 1:male, 2:unknown\n",
    "matrix['gender'].fillna(2, inplace=True)\n",
    "matrix['age_range'] = matrix['age_range'].astype('int8')\n",
    "matrix['gender'] = matrix['gender'].astype('int8')\n",
    "matrix['label'] = matrix['label'].astype('str')\n",
    "matrix['user_id'] = matrix['user_id'].astype('int32')\n",
    "matrix['merchant_id'] = matrix['merchant_id'].astype('int32')\n",
    "del user_info, train_data1\n",
    "gc.collect()\n",
    "print(matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user_id  merchant_id label origin  prob  age_range  gender    u1   u2  \\\n",
      "0        16497         1203   0.0  train   NaN          0       1    46   29   \n",
      "1         1950          946   0.0  train   NaN          2       0   365  198   \n",
      "2        10829         2278   0.0  train   NaN          3       0    47   31   \n",
      "3         7974          951   0.0  train   NaN          0       1   234  105   \n",
      "4        14604         1892   0.0  train   NaN          7       0   186  106   \n",
      "...        ...          ...   ...    ...   ...        ...     ...   ...  ...   \n",
      "23888     2157         1748   nan   test   0.0          0       0   128   97   \n",
      "23889     2673          798   nan   test   0.0          3       0  1286  540   \n",
      "23890    11847          639   nan   test   0.0          2       1     9    8   \n",
      "23891    11847         3953   nan   test   0.0          2       1     9    8   \n",
      "23892    19079         2954   nan   test   0.0          4       0   197   85   \n",
      "\n",
      "       u3  u4  u5        u6      u7  u8    u9   u10  \n",
      "0      12  16  16  4.933333    45.0 NaN   1.0   NaN  \n",
      "1      46  46  45  5.866667   313.0 NaN  21.0  31.0  \n",
      "2      14  15  17  5.833333    42.0 NaN   5.0   NaN  \n",
      "3      23  35  36  5.833333   177.0 NaN  11.0  46.0  \n",
      "4      34  40  39  5.866667   147.0 NaN  25.0  14.0  \n",
      "...    ..  ..  ..       ...     ...  ..   ...   ...  \n",
      "23888  28  39  40  5.816667   122.0 NaN   6.0   NaN  \n",
      "23889  55  93  96  6.000000  1182.0 NaN  16.0  88.0  \n",
      "23890   7   7   7  5.783333     7.0 NaN   2.0   NaN  \n",
      "23891   7   7   7  5.783333     7.0 NaN   2.0   NaN  \n",
      "23892  36  39  40  5.916667   159.0 NaN  31.0   7.0  \n",
      "\n",
      "[23893 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "# User特征处理\n",
    "groups = user_log.groupby(['user_id'])\n",
    "# 用户交互行为数量 u1\n",
    "temp = groups.size().reset_index().rename(columns={0:'u1'})\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\n",
    "# 使用agg 基于列的聚合操作，统计唯一值的个数 item_id, cat_id, merchant_id, brand_id\n",
    "#temp = groups['item_id', 'cat_id', 'merchant_id', 'brand_id'].nunique().reset_index().rename(columns={'item_id':'u2', 'cat_id':'u3', 'merchant_id':'u4', 'brand_id':'u5'})\n",
    "temp = groups['item_id'].agg([('u2', 'nunique')]).reset_index()\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\n",
    "temp = groups['cat_id'].agg([('u3', 'nunique')]).reset_index()\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\n",
    "temp = groups['merchant_id'].agg([('u4', 'nunique')]).reset_index()\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\n",
    "temp = groups['brand_id'].agg([('u5', 'nunique')]).reset_index()\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\n",
    "\n",
    "# 时间间隔特征 u6 按照小时\n",
    "temp = groups['time_stamp'].agg([('F_time', 'min'), ('L_time', 'max')]).reset_index()\n",
    "temp['u6'] = (temp['L_time'] - temp['F_time']).dt.seconds/3600\n",
    "matrix = matrix.merge(temp[['user_id', 'u6']], on='user_id', how='left')\n",
    "# 统计action_type为0，1，2，3的个数（原始操作，没有补0）\n",
    "temp = groups['action_type'].value_counts().unstack().reset_index().rename(columns={0:'u7', 1:'u8', 2:'u9', 3:'u10'})\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\n",
    "print(matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user_id  merchant_id label origin  prob  age_range  gender    u1   u2  \\\n",
      "0        16497         1203   0.0  train   NaN          0       1    46   29   \n",
      "1         1950          946   0.0  train   NaN          2       0   365  198   \n",
      "2        10829         2278   0.0  train   NaN          3       0    47   31   \n",
      "3         7974          951   0.0  train   NaN          0       1   234  105   \n",
      "4        14604         1892   0.0  train   NaN          7       0   186  106   \n",
      "...        ...          ...   ...    ...   ...        ...     ...   ...  ...   \n",
      "23888     2157         1748   nan   test   0.0          0       0   128   97   \n",
      "23889     2673          798   nan   test   0.0          3       0  1286  540   \n",
      "23890    11847          639   nan   test   0.0          2       1     9    8   \n",
      "23891    11847         3953   nan   test   0.0          2       1     9    8   \n",
      "23892    19079         2954   nan   test   0.0          4       0   197   85   \n",
      "\n",
      "       u3  ...    m1   m2   m3  m4  m5      m6    m7     m8     m9   m10  \n",
      "0      12  ...  1915  408  175  19   2  1639.0   4.0  201.0   71.0  3518  \n",
      "1      46  ...  1965  292  320   6   3  1809.0   6.0  104.0   46.0  2816  \n",
      "2      14  ...  1125  254   72  12   2   928.0   5.0  138.0   54.0  2604  \n",
      "3      23  ...   574  210  117   8   2   483.0   1.0   63.0   27.0  1932  \n",
      "4      34  ...  6852  664  554  69   3  6028.0  27.0  473.0  324.0  5471  \n",
      "...    ..  ...   ...  ...  ...  ..  ..     ...   ...    ...    ...   ...  \n",
      "23888  28  ...    72   33   14   2   1    66.0   NaN    2.0    4.0   356  \n",
      "23889  55  ...  4892  907  109  20   2  4323.0  12.0  304.0  253.0  8650  \n",
      "23890   7  ...   480  201    9   2   2   418.0   1.0   49.0   12.0  1943  \n",
      "23891   7  ...   515  171   31   7   3   434.0   3.0   68.0   10.0   540  \n",
      "23892  36  ...  2409  511  133  31   5  1955.0   6.0  300.0  148.0  4497  \n",
      "\n",
      "[23893 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "# 商家特征处理\n",
    "groups = user_log.groupby(['merchant_id'])\n",
    "# 商家被交互行为数量 m1\n",
    "temp = groups.size().reset_index().rename(columns={0:'m1'})\n",
    "matrix = matrix.merge(temp, on='merchant_id', how='left')\n",
    "# 统计商家被交互的user_id, item_id, cat_id, brand_id 唯一值\n",
    "temp = groups['user_id', 'item_id', 'cat_id', 'brand_id'].nunique().reset_index().rename(columns={'user_id':'m2', 'item_id':'m3', 'cat_id':'m4', 'brand_id':'m5'})\n",
    "matrix = matrix.merge(temp, on='merchant_id', how='left')\n",
    "# 统计商家被交互的action_type 唯一值\n",
    "temp = groups['action_type'].value_counts().unstack().reset_index().rename(columns={0:'m6', 1:'m7', 2:'m8', 3:'m9'})\n",
    "matrix = matrix.merge(temp, on='merchant_id', how='left')\n",
    "# 按照merchant_id 统计随机负采样的个数\n",
    "temp = train_data[train_data['label']==-1].groupby(['merchant_id']).size().reset_index().rename(columns={0:'m10'})\n",
    "matrix = matrix.merge(temp, on='merchant_id', how='left')\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:5: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        user_id  merchant_id       um9\n",
      "0             0          186  0.883333\n",
      "1             0          202  0.000000\n",
      "2             0          523  0.000000\n",
      "3             0          774  0.000000\n",
      "4             0          956  0.000000\n",
      "...         ...          ...       ...\n",
      "635221    19111         2874  0.000000\n",
      "635222    19111         3833  0.000000\n",
      "635223    19111         4480  0.000000\n",
      "635224    19111         4522  0.000000\n",
      "635225    19111         4950  0.000000\n",
      "\n",
      "[635226 rows x 3 columns]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "       user_id  merchant_id label origin  prob  age_range  gender    u1   u2  \\\n",
      "0        16497         1203   0.0  train   NaN          0       1    46   29   \n",
      "1         1950          946   0.0  train   NaN          2       0   365  198   \n",
      "2        10829         2278   0.0  train   NaN          3       0    47   31   \n",
      "3         7974          951   0.0  train   NaN          0       1   234  105   \n",
      "4        14604         1892   0.0  train   NaN          7       0   186  106   \n",
      "...        ...          ...   ...    ...   ...        ...     ...   ...  ...   \n",
      "23888     2157         1748   nan   test   0.0          0       0   128   97   \n",
      "23889     2673          798   nan   test   0.0          3       0  1286  540   \n",
      "23890    11847          639   nan   test   0.0          2       1     9    8   \n",
      "23891    11847         3953   nan   test   0.0          2       1     9    8   \n",
      "23892    19079         2954   nan   test   0.0          4       0   197   85   \n",
      "\n",
      "       u3  ...   m10  um1  um2  um3  um4   um5  um6  um7  um8       um9  \n",
      "0      12  ...  3518    8    4    2    1   7.0  NaN  1.0  NaN  0.016667  \n",
      "1      46  ...  2816   42   14    2    1  34.0  NaN  7.0  1.0  0.016667  \n",
      "2      14  ...  2604    2    1    1    1   1.0  NaN  1.0  NaN  0.000000  \n",
      "3      23  ...  1932   11    4    1    1  10.0  NaN  1.0  NaN  0.016667  \n",
      "4      34  ...  5471   19   10    6    1  10.0  NaN  9.0  NaN  0.016667  \n",
      "...    ..  ...   ...  ...  ...  ...  ...   ...  ...  ...  ...       ...  \n",
      "23888  28  ...   356    9    1    1    1   8.0  NaN  1.0  NaN  0.066667  \n",
      "23889  55  ...  8650   42   15   11    1  35.0  NaN  4.0  3.0  2.783333  \n",
      "23890   7  ...  1943    2    1    1    1   1.0  NaN  1.0  NaN  0.000000  \n",
      "23891   7  ...   540    1    1    1    1   NaN  NaN  1.0  NaN  0.000000  \n",
      "23892  36  ...  4497    4    2    2    1   1.0  NaN  2.0  1.0  0.050000  \n",
      "\n",
      "[23893 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "# 按照user_id, merchant_id分组\n",
    "groups = user_log.groupby(['user_id', 'merchant_id'])\n",
    "temp = groups.size().reset_index().rename(columns={0:'um1'}) #统计行为个数\n",
    "matrix = matrix.merge(temp, on=['user_id', 'merchant_id'], how='left')\n",
    "temp = groups['item_id', 'cat_id', 'brand_id'].nunique().reset_index().rename(columns={'item_id':'um2', 'cat_id':'um3', 'brand_id':'um4'}) #统计item_id, cat_id, brand_id唯一个数\n",
    "matrix = matrix.merge(temp, on=['user_id', 'merchant_id'], how='left')\n",
    "temp = groups['action_type'].value_counts().unstack().reset_index().rename(columns={0:'um5', 1:'um6', 2:'um7', 3:'um8'})#统计不同action_type唯一个数\n",
    "matrix = matrix.merge(temp, on=['user_id', 'merchant_id'], how='left')\n",
    "temp = groups['time_stamp'].agg([('first', 'min'), ('last', 'max')]).reset_index()\n",
    "temp['um9'] = (temp['last'] - temp['first']).dt.seconds/3600\n",
    "temp.drop(['first', 'last'], axis=1, inplace=True)\n",
    "print(temp)\n",
    "print('-'*100)\n",
    "matrix = matrix.merge(temp, on=['user_id', 'merchant_id'], how='left') #统计时间间隔\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user_id  merchant_id label origin  prob    u1   u2  u3  u4  u5  ...  \\\n",
      "0        16497         1203   0.0  train   0.0    46   29  12  16  16  ...   \n",
      "1         1950          946   0.0  train   0.0   365  198  46  46  45  ...   \n",
      "2        10829         2278   0.0  train   0.0    47   31  14  15  17  ...   \n",
      "3         7974          951   0.0  train   0.0   234  105  23  35  36  ...   \n",
      "4        14604         1892   0.0  train   0.0   186  106  34  40  39  ...   \n",
      "...        ...          ...   ...    ...   ...   ...  ...  ..  ..  ..  ...   \n",
      "23888     2157         1748   nan   test   0.0   128   97  28  39  40  ...   \n",
      "23889     2673          798   nan   test   0.0  1286  540  55  93  96  ...   \n",
      "23890    11847          639   nan   test   0.0     9    8   7   7   7  ...   \n",
      "23891    11847         3953   nan   test   0.0     9    8   7   7   7  ...   \n",
      "23892    19079         2954   nan   test   0.0   197   85  36  39  40  ...   \n",
      "\n",
      "       age_2  age_3  age_4  age_5  age_6  age_7  age_8  g_0  g_1  g_2  \n",
      "0          0      0      0      0      0      0      0    0    1    0  \n",
      "1          1      0      0      0      0      0      0    1    0    0  \n",
      "2          0      1      0      0      0      0      0    1    0    0  \n",
      "3          0      0      0      0      0      0      0    0    1    0  \n",
      "4          0      0      0      0      0      1      0    1    0    0  \n",
      "...      ...    ...    ...    ...    ...    ...    ...  ...  ...  ...  \n",
      "23888      0      0      0      0      0      0      0    1    0    0  \n",
      "23889      0      1      0      0      0      0      0    1    0    0  \n",
      "23890      1      0      0      0      0      0      0    0    1    0  \n",
      "23891      1      0      0      0      0      0      0    0    1    0  \n",
      "23892      0      0      1      0      0      0      0    1    0    0  \n",
      "\n",
      "[23893 rows x 48 columns]\n"
     ]
    }
   ],
   "source": [
    "#用户购买点击比\n",
    "matrix['r1'] = matrix['u9']/matrix['u7'] \n",
    "#商家购买点击比\n",
    "matrix['r2'] = matrix['m8']/matrix['m6'] \n",
    "#不同用户不同商家购买点击比\n",
    "matrix['r3'] = matrix['um7']/matrix['um5']\n",
    "matrix.fillna(0, inplace=True)\n",
    "# # 修改age_range字段名称为 age_0, age_1, age_2... age_8\n",
    "temp = pd.get_dummies(matrix['age_range'], prefix='age')\n",
    "matrix = pd.concat([matrix, temp], axis=1)\n",
    "temp = pd.get_dummies(matrix['gender'], prefix='g')\n",
    "matrix = pd.concat([matrix, temp], axis=1)\n",
    "matrix.drop(['age_range', 'gender'], axis=1, inplace=True)\n",
    "print(matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:5: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user_id  merchant_id label origin  prob    u1   u2  u3  u4  u5  ...  \\\n",
      "0        16497         1203   0.0  train   0.0    46   29  12  16  16  ...   \n",
      "1         1950          946   0.0  train   0.0   365  198  46  46  45  ...   \n",
      "2        10829         2278   0.0  train   0.0    47   31  14  15  17  ...   \n",
      "3         7974          951   0.0  train   0.0   234  105  23  35  36  ...   \n",
      "4        14604         1892   0.0  train   0.0   186  106  34  40  39  ...   \n",
      "...        ...          ...   ...    ...   ...   ...  ...  ..  ..  ..  ...   \n",
      "23888     2157         1748   nan   test   0.0   128   97  28  39  40  ...   \n",
      "23889     2673          798   nan   test   0.0  1286  540  55  93  96  ...   \n",
      "23890    11847          639   nan   test   0.0     9    8   7   7   7  ...   \n",
      "23891    11847         3953   nan   test   0.0     9    8   7   7   7  ...   \n",
      "23892    19079         2954   nan   test   0.0   197   85  36  39  40  ...   \n",
      "\n",
      "       age_4  age_5  age_6  age_7  age_8  g_0  g_1  g_2  \\\n",
      "0          0      0      0      0      0    0    1    0   \n",
      "1          0      0      0      0      0    1    0    0   \n",
      "2          0      0      0      0      0    1    0    0   \n",
      "3          0      0      0      0      0    0    1    0   \n",
      "4          0      0      0      1      0    1    0    0   \n",
      "...      ...    ...    ...    ...    ...  ...  ...  ...   \n",
      "23888      0      0      0      0      0    1    0    0   \n",
      "23889      0      0      0      0      0    1    0    0   \n",
      "23890      0      0      0      0      0    0    1    0   \n",
      "23891      0      0      0      0      0    0    1    0   \n",
      "23892      1      0      0      0      0    1    0    0   \n",
      "\n",
      "                                        hist_merchant_id  \\\n",
      "0      [3735, 1203, 3490, 2968, 3510, 3510, 3388, 610...   \n",
      "1      [1867, 3891, 141, 420, 3891, 420, 141, 1867, 1...   \n",
      "2      [604, 1807, 2950, 604, 2101, 1807, 1807, 1807,...   \n",
      "3      [644, 644, 951, 644, 644, 644, 3176, 951, 644,...   \n",
      "4      [1885, 40, 172, 1727, 1727, 1892, 1727, 1727, ...   \n",
      "...                                                  ...   \n",
      "23888  [4770, 4770, 3490, 3490, 215, 215, 215, 215, 2...   \n",
      "23889  [4172, 2418, 3734, 3212, 2418, 4346, 4172, 417...   \n",
      "23890  [1955, 203, 4842, 4842, 3953, 639, 639, 4308, ...   \n",
      "23891  [1955, 203, 4842, 4842, 3953, 639, 639, 4308, ...   \n",
      "23892  [4375, 1318, 2580, 3169, 4375, 1892, 3223, 431...   \n",
      "\n",
      "                                        hist_action_type  \n",
      "0      [1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
      "1      [4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
      "2      [3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
      "3      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, ...  \n",
      "4      [1, 1, 1, 4, 1, 1, 1, 1, 1, 4, 1, 4, 3, 1, 1, ...  \n",
      "...                                                  ...  \n",
      "23888  [1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
      "23889  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
      "23890                        [1, 1, 1, 1, 3, 3, 1, 1, 1]  \n",
      "23891                        [1, 1, 1, 1, 3, 3, 1, 1, 1]  \n",
      "23892  [1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 1, ...  \n",
      "\n",
      "[23893 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "lbe_action_type={0:1,1:2,2:3,3:4}\n",
    "user_log['action_type']=user_log['action_type'].map(lbe_action_type)\n",
    "# 用户行为sequence\n",
    "# 把user_log里同user的这些数据合并成一个list\n",
    "temp=pd.DataFrame(user_log.groupby('user_id')['merchant_id','action_type'].agg(lambda x:list(x)))\n",
    "# 列名称改成hist_merchant_id 和 hist_action_type \n",
    "temp.columns=['hist_merchant_id','hist_action_type']\n",
    "#print(temp)\n",
    "matrix = matrix.merge(temp, on=['user_id'], how='left') #统计时间间隔\n",
    "print(matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user_id  merchant_id  prob   u1   u2  u3  u4  u5        u6     u7  ...  \\\n",
      "0        16497         1203   0.0   46   29  12  16  16  4.933333   45.0  ...   \n",
      "1         1950          946   0.0  365  198  46  46  45  5.866667  313.0  ...   \n",
      "2        10829         2278   0.0   47   31  14  15  17  5.833333   42.0  ...   \n",
      "3         7974          951   0.0  234  105  23  35  36  5.833333  177.0  ...   \n",
      "4        14604         1892   0.0  186  106  34  40  39  5.866667  147.0  ...   \n",
      "...        ...          ...   ...  ...  ...  ..  ..  ..       ...    ...  ...   \n",
      "17832    18547         3825   0.0   40   24  13  14  15  4.916667   27.0  ...   \n",
      "17833    18693         3443   0.0   15   12  10  10  10  6.000000   10.0  ...   \n",
      "17834     4034         4172   0.0   16   14   8  11  12  5.833333   15.0  ...   \n",
      "17835    16017          993   0.0   33   25  12  15  15  4.916667   31.0  ...   \n",
      "17836     7308         4723   0.0   94   50  18  24  22  5.766667   80.0  ...   \n",
      "\n",
      "       age_4  age_5  age_6  age_7  age_8  g_0  g_1  g_2  \\\n",
      "0          0      0      0      0      0    0    1    0   \n",
      "1          0      0      0      0      0    1    0    0   \n",
      "2          0      0      0      0      0    1    0    0   \n",
      "3          0      0      0      0      0    0    1    0   \n",
      "4          0      0      0      1      0    1    0    0   \n",
      "...      ...    ...    ...    ...    ...  ...  ...  ...   \n",
      "17832      0      0      1      0      0    0    1    0   \n",
      "17833      0      0      0      0      0    1    0    0   \n",
      "17834      0      0      0      0      0    1    0    0   \n",
      "17835      0      0      1      0      0    1    0    0   \n",
      "17836      0      0      0      0      0    1    0    0   \n",
      "\n",
      "                                        hist_merchant_id  \\\n",
      "0      [3735, 1203, 3490, 2968, 3510, 3510, 3388, 610...   \n",
      "1      [1867, 3891, 141, 420, 3891, 420, 141, 1867, 1...   \n",
      "2      [604, 1807, 2950, 604, 2101, 1807, 1807, 1807,...   \n",
      "3      [644, 644, 951, 644, 644, 644, 3176, 951, 644,...   \n",
      "4      [1885, 40, 172, 1727, 1727, 1892, 1727, 1727, ...   \n",
      "...                                                  ...   \n",
      "17832  [2647, 826, 4137, 2941, 4137, 4137, 4137, 4137...   \n",
      "17833  [937, 4289, 2812, 4289, 3119, 3119, 3119, 3119...   \n",
      "17834  [3685, 1737, 1737, 1588, 4172, 1737, 1588, 353...   \n",
      "17835  [584, 993, 993, 993, 1138, 1138, 4497, 1138, 1...   \n",
      "17836  [3662, 3662, 3662, 3662, 3662, 3662, 3662, 366...   \n",
      "\n",
      "                                        hist_action_type  \n",
      "0      [1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
      "1      [4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
      "2      [3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
      "3      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, ...  \n",
      "4      [1, 1, 1, 4, 1, 1, 1, 1, 1, 4, 1, 4, 3, 1, 1, ...  \n",
      "...                                                  ...  \n",
      "17832  [1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, ...  \n",
      "17833  [1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 3, 3, 3, 1, ...  \n",
      "17834  [1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
      "17835  [1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
      "17836  [3, 1, 3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 3, ...  \n",
      "\n",
      "[17837 rows x 48 columns]\n"
     ]
    }
   ],
   "source": [
    "# 截取，不缺到定长M个\n",
    "M=500\n",
    "for feature in ['hist_merchant_id','hist_action_type']:\n",
    "    matrix[feature]=matrix[feature].map(lambda x:np.array(x+[0]*(M-len(x)))[:M])\n",
    "\n",
    "# 分割训练数据和测试数据\n",
    "train_data = matrix[matrix['origin'] == 'train'].drop(['origin'], axis=1)\n",
    "test_data = matrix[matrix['origin'] == 'test'].drop(['label', 'origin'], axis=1)\n",
    "train_X, train_y = train_data.drop(['label'], axis=1), train_data['label']\n",
    "print(train_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用DIN模型\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import log_loss\n",
    "from deepctr.feature_column import SparseFeat, VarLenSparseFeat, DenseFeat,get_feature_names\n",
    "from deepctr.models import DIN, DIEN, DSIN\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id\n",
      "14488\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/initializers.py:143: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "merchant_id\n",
      "1856\n",
      "prob\n",
      "1\n",
      "u1\n",
      "825\n",
      "u2\n",
      "539\n",
      "u3\n",
      "124\n",
      "u4\n",
      "246\n",
      "u5\n",
      "237\n",
      "u6\n",
      "184\n",
      "u7\n",
      "772\n",
      "u8\n",
      "17\n",
      "u9\n",
      "79\n",
      "u10\n",
      "161\n",
      "m1\n",
      "805\n",
      "m2\n",
      "406\n",
      "m3\n",
      "292\n",
      "m4\n",
      "56\n",
      "m5\n",
      "35\n",
      "m6\n",
      "757\n",
      "m7\n",
      "23\n",
      "m8\n",
      "208\n",
      "m9\n",
      "163\n",
      "m10\n",
      "1294\n",
      "um1\n",
      "170\n",
      "um2\n",
      "94\n",
      "um3\n",
      "22\n",
      "um4\n",
      "12\n",
      "um5\n",
      "166\n",
      "um6\n",
      "8\n",
      "um7\n",
      "10\n",
      "um8\n",
      "26\n",
      "um9\n",
      "184\n",
      "r1\n",
      "3269\n",
      "r2\n",
      "1413\n",
      "r3\n",
      "394\n",
      "age_0\n",
      "2\n",
      "age_2\n",
      "2\n",
      "age_3\n",
      "2\n",
      "age_4\n",
      "2\n",
      "age_5\n",
      "2\n",
      "age_6\n",
      "2\n",
      "age_7\n",
      "2\n",
      "age_8\n",
      "2\n",
      "g_0\n",
      "2\n",
      "g_1\n",
      "2\n",
      "g_2\n",
      "2\n",
      "action_type\n",
      "1\n",
      "(17837,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17837"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X['action_type']=3\n",
    "feature_columns = []\n",
    "for column in train_X.columns:\n",
    "  if column != 'hist_merchant_id' and column != 'hist_action_type':\n",
    "    print(column)\n",
    "    num = train_X[column].nunique()\n",
    "    if num > 10000:\n",
    "        dim = 10\n",
    "    else:\n",
    "        if num > 1000:\n",
    "            dim = 8\n",
    "        else:\n",
    "            dim = 4\n",
    "    print(num)\n",
    "    if column  == 'user_id':\n",
    "        feature_columns += [SparseFeat(column, 19111+1, embedding_dim=dim)]\n",
    "    elif column  == 'merchant_id':\n",
    "        feature_columns += [SparseFeat(column, 4994+1, embedding_dim=dim)]\n",
    "    elif column  == 'action_type':\n",
    "        feature_columns += [SparseFeat(column, 4+1, embedding_dim=dim)]\n",
    "    else:\n",
    "        feature_columns += [DenseFeat(column, 1)]\n",
    "\n",
    "print(train_X['hist_merchant_id'].shape)\n",
    "len(train_X['hist_merchant_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M= 500\n"
     ]
    }
   ],
   "source": [
    "print('M=', M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SparseFeat(name='user_id', vocabulary_size=19112, embedding_dim=10, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x7f874de14690>, embedding_name='user_id', group_name='default_group', trainable=True), SparseFeat(name='merchant_id', vocabulary_size=4995, embedding_dim=8, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x7f8713039650>, embedding_name='merchant_id', group_name='default_group', trainable=True), DenseFeat(name='prob', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='u1', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='u2', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='u3', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='u4', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='u5', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='u6', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='u7', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='u8', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='u9', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='u10', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='m1', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='m2', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='m3', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='m4', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='m5', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='m6', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='m7', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='m8', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='m9', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='m10', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='um1', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='um2', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='um3', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='um4', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='um5', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='um6', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='um7', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='um8', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='um9', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='r1', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='r2', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='r3', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='age_0', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='age_2', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='age_3', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='age_4', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='age_5', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='age_6', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='age_7', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='age_8', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='g_0', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='g_1', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='g_2', dimension=1, dtype='float32', transform_fn=None), SparseFeat(name='action_type', vocabulary_size=5, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x7f8748373050>, embedding_name='action_type', group_name='default_group', trainable=True), VarLenSparseFeat(sparsefeat=SparseFeat(name='hist_merchant_id', vocabulary_size=4995, embedding_dim=8, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x7f8748353410>, embedding_name='merchant_id', group_name='default_group', trainable=True), maxlen=500, combiner='mean', length_name=None, weight_name=None, weight_norm=True), VarLenSparseFeat(sparsefeat=SparseFeat(name='hist_action_type', vocabulary_size=5, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x7f8748386c50>, embedding_name='action_type', group_name='default_group', trainable=True), maxlen=500, combiner='mean', length_name=None, weight_name=None, weight_norm=True)]\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (lambda), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'attention_sequence_pooling_layer/local_activation_unit/kernel:0' shape=(40, 1) dtype=float32>\n",
      "  <tf.Variable 'attention_sequence_pooling_layer/local_activation_unit/bias:0' shape=(1,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17837/17837 [00:00<00:00, 1926254.55it/s]\n",
      "100%|██████████| 17837/17837 [00:00<00:00, 2100803.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 12s 443ms/step - loss: 1.9274 - binary_crossentropy: 1.9274 - val_loss: 0.9338 - val_binary_crossentropy: 0.9338\n",
      "Epoch 2/10\n",
      "28/28 [==============================] - 10s 345ms/step - loss: 0.9135 - binary_crossentropy: 0.9135 - val_loss: 0.9338 - val_binary_crossentropy: 0.9338\n",
      "Epoch 3/10\n",
      "28/28 [==============================] - 10s 356ms/step - loss: 0.9135 - binary_crossentropy: 0.9135 - val_loss: 0.9338 - val_binary_crossentropy: 0.9338\n",
      "Epoch 4/10\n",
      "28/28 [==============================] - 10s 353ms/step - loss: 0.9135 - binary_crossentropy: 0.9135 - val_loss: 0.9338 - val_binary_crossentropy: 0.9338\n",
      "Epoch 5/10\n",
      "28/28 [==============================] - 10s 350ms/step - loss: 0.9135 - binary_crossentropy: 0.9135 - val_loss: 0.9338 - val_binary_crossentropy: 0.9338\n",
      "Epoch 6/10\n",
      "28/28 [==============================] - 10s 363ms/step - loss: 0.9135 - binary_crossentropy: 0.9135 - val_loss: 0.9338 - val_binary_crossentropy: 0.9338\n",
      "Epoch 7/10\n",
      "28/28 [==============================] - 10s 359ms/step - loss: 0.9135 - binary_crossentropy: 0.9135 - val_loss: 0.9338 - val_binary_crossentropy: 0.9338\n",
      "Epoch 8/10\n",
      "28/28 [==============================] - 11s 381ms/step - loss: 0.9135 - binary_crossentropy: 0.9135 - val_loss: 0.9338 - val_binary_crossentropy: 0.9338\n",
      "Epoch 9/10\n",
      "28/28 [==============================] - 11s 376ms/step - loss: 0.9135 - binary_crossentropy: 0.9135 - val_loss: 0.9338 - val_binary_crossentropy: 0.9338\n",
      "Epoch 10/10\n",
      "28/28 [==============================] - 10s 361ms/step - loss: 0.9135 - binary_crossentropy: 0.9135 - val_loss: 0.9338 - val_binary_crossentropy: 0.9338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6056/6056 [00:00<00:00, 1041781.03it/s]\n",
      "100%|██████████| 6056/6056 [00:00<00:00, 499414.19it/s]\n"
     ]
    }
   ],
   "source": [
    "# maxlen为历史信息的长度，vocabulary_size为onehot的长度\n",
    "feature_columns += [VarLenSparseFeat(SparseFeat('hist_merchant_id',vocabulary_size=4994+1, embedding_dim=8, embedding_name='merchant_id'),maxlen=M),\n",
    "                   VarLenSparseFeat(SparseFeat('hist_action_type',  vocabulary_size=4+1, embedding_dim=4, embedding_name='action_type'),maxlen=M)]\n",
    "hist_features=['merchant_id','action_type']\n",
    "print(feature_columns)\n",
    "\n",
    "# 使用DIN模型\n",
    "model=DIN(feature_columns, hist_features)\n",
    "# 使用Adam优化器，二分类的交叉熵\n",
    "model.compile('adam', 'binary_crossentropy', metrics=['binary_crossentropy'])\n",
    "\n",
    "# 组装train_model_input，得到feature names，将train_X转换为字典格式\n",
    "feature_names=list(train_X.columns)\n",
    "train_model_input = {name:train_X[name].values for name in feature_names}\n",
    "# histroy输入必须是二维数组\n",
    "from tqdm import tqdm\n",
    "for fea in ['hist_merchant_id','hist_action_type']:\n",
    "    l = []\n",
    "    for i in tqdm(train_model_input[fea]):\n",
    "        l.append(i)\n",
    "    train_model_input[fea]=np.array(l)\n",
    "history = model.fit(train_model_input, train_y.map(float), verbose=True, epochs=10, validation_split=0.2,batch_size=512)\n",
    "\n",
    "# 转换test__model_input\n",
    "test_data['action_type']=3\n",
    "test_model_input = {name:test_data[name].values for name in feature_names}\n",
    "from tqdm import tqdm\n",
    "for fea in ['hist_merchant_id','hist_action_type']:\n",
    "    l = []\n",
    "    for i in tqdm(test_model_input[fea]):\n",
    "        l.append(i)\n",
    "    test_model_input[fea]=np.array(l)\n",
    "\n",
    "# 得到预测结果\n",
    "prob = model.predict(test_model_input)\n",
    "submission['prob'] = prob\n",
    "submission.drop(['origin'], axis=1, inplace=True)\n",
    "submission.to_csv('prediction_small.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
